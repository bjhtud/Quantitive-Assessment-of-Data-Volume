
# Quantitative Assessment of Data Volume

This repository contains the source code used in the experiments of the paper **"Quantitive Assessment of Data Volume
Requirements for Reliable Machine Learning
Analysis"**. It includes scripts for automated model training using Auto-sklearn and statistical confidence interval (CI) analysis of model performance.

---

## Contents

- `modeling.py`: Trains regression models using Auto-sklearn and evaluates performance (R² score).
- `CI_compute.py`: Computes confidence intervals (CI) for the R² scores across multiple random seeds.
- `dataset/meta.csv`: A metadata file containing the paths and information of all datasets used.
- `result/`: Output folder automatically generated by the scripts.
- `utils/data_process_meta.py`: Helper function for loading and preprocessing datasets based on metadata.

---

## Requirements

- Python 3.7+
- Required libraries:
  - `numpy`
  - `pandas`
  - `scipy`
  - `scikit-learn`
  - `matplotlib`
  - `auto-sklearn`

To install all dependencies:
```bash
pip install numpy pandas scipy scikit-learn matplotlib auto-sklearn
```

---

## 1. Script: `modeling.py`

### Purpose

This script performs automated regression modeling using [Auto-sklearn](https://automl.github.io/auto-sklearn/master/). It evaluates the model on a test set and saves both the R² score and a plot of performance over time.

The script uses the metadata file `dataset/meta.csv` to locate and load the appropriate dataset for training and evaluation.

### Usage

```bash
python modeling.py --seed <int> --test_size <percent> --run_time <minutes> --dataset_name <name>
```

### Parameters

| Argument        | Description                                   | Example            |
|-----------------|-----------------------------------------------|--------------------|
| `--seed`        | Random seed for reproducibility               | `--seed 42`        |
| `--test_size`   | Percentage of test data (e.g., `20` means 20%) | `--test_size 20`   |
| `--run_time`    | Total training time per experiment in minutes | `--run_time 15`    |
| `--dataset_name`| Dataset name as listed in `meta.csv`          | `--dataset_name uci-concrete` |   

### Output

Results are saved in:
```
result/<dataset_name>/<test_size>/<seed>/
```
Files include:
- `result.json`: Contains R² score and experiment metadata.
- `performance_over_time.png`: A plot showing Auto-sklearn model performance over time.

---

## 2. Script: `CI_compute.py`

### Purpose

This script computes lower confidence limits (LCL) for the R² scores obtained from multiple runs (different seeds). It estimates CIs for significance levels of 95%, 90%, and 80%.

### Usage

```bash
python CI_compute.py
```

### Output

In each folder:
```
result/<dataset_name>/<test_size>/
```
The script generates files:
- `CI_95%.json`
- `CI_90%.json`
- `CI_80%.json`

Each file contains:
```json
{
  "alpha": 0.05,
  "LCL": <value>
}
```

---

## Dataset and Metadata

The file `dataset/meta.csv` acts as a metadata file describing all available datasets. It contains information such as dataset names and file paths. The script `modeling.py` accesses the actual datasets using this metadata. This allows easy management of multiple datasets in a unified manner.

---

## Reproducibility Steps

1. **Prepare the data**  
   Ensure `dataset/meta.csv` exists and is properly formatted with paths to your datasets.

2. **Run model training with different seeds**  
   Example:
   ```bash
   for seed in 0 1 2 3 4; do
       python modeling.py --seed $seed --test_size 20 --run_time 10 --dataset_name Xiong_2014
   done
   ```

3. **Compute confidence intervals**
   ```bash
   python CI_compute.py
   ```

4. **View results**
   - R² scores: in `result.json` files.
   - Confidence intervals: in `CI_*.json` files.
   - Learning curve: in `performance_over_time.png`.

---

## License

This project is licensed under the MIT License - see the [LICENSE](LICENSE.txt) file for details.

---

## Citation

If you use this code or dataset, please cite the associated paper:

```
@article{your2025paper,
  title   = {},
  author  = {},
  journal = {},
  year    = {2025},
  ...     = {...}
}
```

---

For questions or reproducibility issues, please contact: []
